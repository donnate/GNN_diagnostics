{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcde3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file specific libraries\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import math, random, torch, collections, time, torch.nn.functional as F, networkx as nx, matplotlib.pyplot as plt, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from IPython.display import clear_output\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import wraps\n",
    "\n",
    "%matplotlib inline\n",
    "import sys,os\n",
    "from models import *\n",
    "from train_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015596fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "===========================================================================================================\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import pandas as pd\n",
    "\n",
    "dataset_name = 'Cora'\n",
    "dataset = Planetoid(root='../data/Planetoid', name=dataset_name, transform=NormalizeFeatures())\n",
    "###\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c73cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#### Simple model\n",
    "\n",
    "model =GNN(input_dim = data.num_features, hidden_dim=252,\n",
    "           output_dim = dataset.num_classes, n_layers=2,\n",
    "           activation ='relu', slope=.1,\n",
    "           device ='cpu',\n",
    "           alpha_res =0., alpha=0.5,\n",
    "           beta=1.,\n",
    "           normalize=False)\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4) #didn't include weight decay\n",
    "train_acc_list, test_acc_list, loss_list, misclassified, predictions = train(500, model, criterion, optimizer, \n",
    "                                                 x= data.x, edge_index= data.edge_index, y=data.y, \n",
    "                                                m=mask(data.train_mask, data.test_mask),\n",
    "                                                scatter_size=30, plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fbd2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74c78982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " F.mse_loss(u, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb744740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 0.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.6147, -0.6425, -1.1681,  ..., -1.2312, -2.9105, -0.9876],\n",
       "         [-0.0281, -2.0336, -1.6827,  ...,  4.0344, -1.7742, -1.6099],\n",
       "         [-1.4779, -2.1740, -0.3025,  ...,  4.4120, -3.9713, -3.5023],\n",
       "         ...,\n",
       "         [ 0.5894,  0.5385, -2.2205,  ..., -1.4522,  0.6031, -0.3671],\n",
       "         [-0.7702, -0.6123, -1.8835,  ..., -0.7678, -1.8863, -2.7292],\n",
       "         [-1.1804, -0.3707, -1.4391,  ..., -0.8305, -2.1603, -3.3164]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " 0.07619693,\n",
       " array([ 1.9922217e-08, -5.9752682e-07, -1.0459329e-06, ...,\n",
       "         4.6757538e-08,  1.5225369e-08,  8.1113596e-09], dtype=float32),\n",
       " 0.772)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_pipeline(model, dataset, data,data.train_mask,\n",
    "                 data.test_mask, 1,\n",
    "                 10,\n",
    "                 original_output=None,\n",
    "                 compute_y_differences=True,\n",
    "                 task='classfication',\n",
    "                 loss_function=torch.nn.CrossEntropyLoss(),\n",
    "                 lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46428956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.special import rel_entr\n",
    "\n",
    "def loo_pipeline(model, dataset, data, train_mask,\n",
    "                 test_mask, which_node,\n",
    "                 n_epochs=200,\n",
    "                 original_output=None,\n",
    "                 compute_y_differences=False,\n",
    "                 task='classfication',\n",
    "                 loss_function=torch.nn.CrossEntropyLoss(),\n",
    "                 lr=0.001):\n",
    "    \"\"\"\n",
    "    model should be the trained model/\n",
    "    original_output = output using the original data, optional\n",
    "    indicate = Boolean\n",
    "    compute_y_differences = Boolean\n",
    "\n",
    "    returns: prediction by the given data,\n",
    "            y_differences (y - y_hat) if compute_y_differences set True,\n",
    "            accuracy of the model trained using the given data\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if original_output is None:\n",
    "        model.eval()\n",
    "        original_output  = model(data.x, data.edge_index)\n",
    "    _, original_predictions = torch.max(original_output.detach(),1)\n",
    "    length = len(data.y[train_mask])\n",
    "    original_accuracy = (original_predictions[test_mask] == data.y[test_mask].detach()).sum().item()/length\n",
    "    original_misclassified = (original_predictions[test_mask] != data.y[test_mask]).numpy()\n",
    "\n",
    "    #### Mask a node, and retrain on the data for each node\n",
    "    new_model = copy.deepcopy(model)\n",
    "    optimizer = torch.optim.Adam(new_model.parameters(), lr=lr, weight_decay=5e-4) \n",
    "    new_mask = copy.deepcopy(train_mask)\n",
    "    new_mask[which_node] = False\n",
    "    train_acc_list, test_acc_list, loss_list, misclassified, predictions = train(n_epochs, new_model, loss_function, optimizer, \n",
    "                                                     x= data.x, edge_index= data.edge_index, y=data.y, \n",
    "                                                     m=mask(new_mask, test_mask),\n",
    "                                                     scatter_size=30, plotting=False)\n",
    "    loo_output  = new_model(data.x, data.edge_index)\n",
    "    _, loo_predictions = torch.max(loo_output.detach(),1)\n",
    "    length = len(data.y[test_mask])\n",
    "    loo_accuracy = (loo_predictions[test_mask] == data.y[test_mask].detach()).sum().item()/length\n",
    "    loo_misclassified = (loo_predictions[test_mask] != data.y[test_mask]).numpy()\n",
    "    if compute_y_differences:\n",
    "        if len(loo_output) != len(original_output):\n",
    "            y_differences = None\n",
    "            print(HERE)\n",
    "        else:\n",
    "            original_scores = torch.nn.functional.softmax(original_output, dim=0).detach().numpy()\n",
    "            loo_scores = torch.nn.functional.softmax(loo_output, dim=0).detach().numpy()\n",
    "            kl = np.mean(rel_entr(original_scores, loo_scores),1)\n",
    "            #print(f\"kl divergence: {kl}\")\n",
    "            y_differences = np.mean(np.linalg.norm(loo_scores - original_scores))\n",
    "            # softmax(original_output) - softmax(new_output) -> difference of the score\n",
    "        # compare two differences / nonnegative version\n",
    "        # KL divergence, take MSE loss\n",
    "\n",
    "        # deeplearning & nonlinear model - embedding solution is unique\n",
    "        # score is more identifiable, as sums up to 1, comparable\n",
    "        # way the model train is end up in diff local minimum\n",
    "        # for x,y,z, to be unique, needs another constraint for ex alpha = 0\n",
    "    else:\n",
    "        y_differences = None\n",
    "        kl = None\n",
    "\n",
    "    return loo_output, y_differences, kl, loo_accuracy\n",
    "\n",
    "\n",
    "def check_pipeline(model, dataset, data, train_mask,\n",
    "                   test_mask,\n",
    "                   n_epochs=200,\n",
    "                   original_output=None,\n",
    "                   indicate=False, \\\n",
    "                   return_prediction=False,\n",
    "                   compute_y_differences=False,\n",
    "                   dimension=32,\n",
    "                   task='classification',\n",
    "                   loss_function=torch.nn.CrossEntropyLoss(),\n",
    "                   lr=0.001):\n",
    "    \"\"\"\n",
    "    model should be the trained model/\n",
    "    original_output = output using the original data, optional\n",
    "    indicate = Boolean\n",
    "    compute_y_differences = Boolean\n",
    "\n",
    "    returns: prediction by the given data,\n",
    "            y_differences (y - y_hat) if compute_y_differences set True,\n",
    "            accuracy of the model trained using the given data\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if original_output is None:\n",
    "        model.eval()\n",
    "        original_output  = model(data.x, data.edge_index)\n",
    "    _, original_predictions = torch.max(original_output.detach(),1)\n",
    "    length = len(data.y[train_mask])\n",
    "    original_accuracy = (original_predictions[test_mask] == data.y[test_mask].detach()).sum().item()/length\n",
    "    original_misclassified = (original_predictions[test_mask] != data.y[test_mask]).numpy()\n",
    "    y_differences = []\n",
    "    kl = []\n",
    "    #### Mask a node, and retrain on the data for each node\n",
    "    for i in torch.where(data.train_mask)[0]:\n",
    "        loo_output, y_prime, kl_prime, loo_accuracy_prime = loo_pipeline(model, dataset, data, train_mask,\n",
    "                 test_mask, which_node=i,\n",
    "                 n_epochs=n_epochs,\n",
    "                 original_output=original_output,\n",
    "                 compute_y_differences=compute_y_differences,\n",
    "                 task=task,\n",
    "                 loss_function=loss_function,\n",
    "                 lr=lr)\n",
    "        y_differences += [y_prime]\n",
    "        kl += [kl_prime]\n",
    "\n",
    "\n",
    "    return new_output, y_differences, kl, new_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38522e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
